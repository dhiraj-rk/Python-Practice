{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7bf67586",
   "metadata": {},
   "source": [
    "### Question.1.Write code to load in this .csv dataset. Start by splitting the dataset using train_test_split method into a train and test partition. Use the test partition as a validation set that gets left out until a final validation step. Use a test size of 10%.\n",
    "\n",
    "### Consider the following scenario: You are using the k-NN classifier model to predict diagnosis from the radius_mean, texture_mean, perimeter_mean and area_mean columns of the breast-cancer-data data set. You have performed a grid search experiment to determine which value of k optimizes the k-NN classifier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44decf70",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV, KFold, cross_val_score\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ccfd08c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load breast cancer dataset\n",
    "df_bc = pd.read_csv(\"breast-cancer-data.csv\")\n",
    "df_bc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29461851",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Get the X and y values\n",
    "X = df_bc[[\"radius_mean\", \"texture_mean\", \"perimeter_mean\", \"area_mean\"]]\n",
    "y = df_bc[\"diagnosis\"]\n",
    "print(X)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eba0ba37",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Partition data into train and test using test size of 10%\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.1, random_state = 0)\n",
    "\n",
    "#Creating a KNN classifier\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "#Creating GridSearchCV\n",
    "\n",
    "#Defining range\n",
    "k_range = list(range(1, 31))\n",
    "print(f\"K range:{k_range}\")\n",
    "\n",
    "#Assigning range to test\n",
    "param_grid = dict(n_neighbors=k_range)\n",
    "print(f\"Parameters:{param_grid}\")\n",
    "\n",
    "#Perform GridSearchCV\n",
    "grid = GridSearchCV(knn, param_grid, cv=10, scoring='accuracy', return_train_score=False)\n",
    "grid.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00659602",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting the best value of hyper parameter - k\n",
    "print(f\"Best value of k that optimizes the k-NN classifier:{grid.best_params_['n_neighbors']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fd361ca",
   "metadata": {},
   "source": [
    "### Question.2. Implement code to realize the scenario above, showing which optimal value of k is found that optimizes the model.  Use only the train part from the original 90-10% split performed above for this process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d3556fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using best k value to the training set\n",
    "\n",
    "best_value_k = grid.best_params_['n_neighbors']\n",
    "knn_classifier = KNeighborsClassifier(n_neighbors = best_value_k )\n",
    "knn_classifier.fit(X_train, y_train)\n",
    "\n",
    "#Predicting diagnosis\n",
    "y_pred = knn_classifier.predict(X_test)\n",
    "\n",
    "#Calculating the accuract\n",
    "acc_score = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy with k={best_value_k} is {acc_score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b79875ee",
   "metadata": {},
   "source": [
    "### Question.3. What is the issue in this paper in model selection that is addressed. How does that apply specifically to our scenario?\n",
    "***\n",
    "\n",
    "#### According to the paper, the issue was noted where the variance of the model selection criterion had the possibility of over-fitting during model selection. And with over-fitting in model selection, undesirable optimistic bias can arise. In the example for kernel ridge regression classifier, when the authors added one thousand independent realisations, the cross-validation estimate of the mean squared error, forming the model selection criterion, decreased. For a short duration, it seemed that the model had improvements, but after approximately 30 to 40 iterations, the test error began to climb. In conclusion, the paper tries to provide the concept that when overfitting in model selection occurs (i.e.when selecting a model or its hyper-parameters) it gives exceptionally well results on the training data but fails to generalize on test data or unseen data. Also, the paper mentions that high variance can lead to over-fitting in model selection and result in poor performance, even when the number of hyper-parameters is relatively small.\n",
    "\n",
    "#### In order to avoid the issue,  the strategies to choose the best model generally involve convex-optimization problems. The paper suggests to implement hyper parameter tuning, k-fold cross-validation among others.\n",
    "\n",
    "#### In our scenario, we are keen on finding the optimum value for our hyper-parameter with low variance and bias. Therefore, GridsearchCV k-fold cross validation algorithm within the hyper parameter tuning is used for our scenario.\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0317d77",
   "metadata": {},
   "source": [
    "### Question.4. Based on your understanding of this issue and recommendations of the paper, write code to implement a solution to the problem that likely affects our given scenario, according to the paperâ€™s main thesis. In your code, compare the new training solution to the old one in terms by testing using the left-out validation set above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1704fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting the data into train, validation and test set\n",
    "X_train_new, X_temp, y_train_new, y_temp = train_test_split(X, y, test_size = 0.20, random_state = 42)\n",
    "X_val, X_test_new, y_val, y_test_new = train_test_split(X_temp, y_temp, test_size = 0.50, random_state = 42)\n",
    "\n",
    "param_knn_4 = {\n",
    "    'n_neighbors': range(1, 11),\n",
    "    'leaf_size': (20, 40),\n",
    "    'p': (1, 2),\n",
    "    'weights': ('uniform', 'distance'),\n",
    "    \n",
    "}\n",
    "\n",
    "param_knn_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d57f8e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_4 = []\n",
    "for i in range(10):\n",
    "    inner_cv = KFold(n_splits = 6, shuffle = True, random_state = i)\n",
    "    grid_search = GridSearchCV(\n",
    "        estimator = KNeighborsClassifier(),\n",
    "        param_grid = param_knn_4,\n",
    "        cv = inner_cv,\n",
    "        n_jobs = 1\n",
    "    )\n",
    "    score = cross_val_score(grid_search, X_train, y = y_train, cv = 5)\n",
    "    score_4.append(score.mean())\n",
    "print(f\"DONE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa7054e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting the best k value\n",
    "best_index = np.argmax(score_4)\n",
    "best_n_neighbors = param_knn_4['n_neighbors'][best_index // 2]\n",
    "best_leaf_size = param_knn_4['leaf_size'][best_index % 2] \n",
    "best_p = param_knn_4['p'][best_index % 2]\n",
    "best_weights = param_knn_4['weights'][best_index %2]\n",
    "#best_metric = param_grid['metric'][best_index % 2]\n",
    "\n",
    "print(f\"The best k value with hyperparameter tuning with train-validation-test split is {best_index}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "195c62d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training KNN with best k value\n",
    "best_knn_4 = KNeighborsClassifier(n_neighbors = best_k_4, leaf_size = best_leaf_size, p = best_p, weights = best_weights) #metric = best_metric)\n",
    "best_knn_4.fit(X_train_new, y_train_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "920e2adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Best validation set\n",
    "validation_accuracy = best_knn_4.score(X_val, y_val)\n",
    "print(f\"Validation accuracy with best hyperparameter values: {validation_accuracy:.4f}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63d6b418",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Best test set\n",
    "test_accuracy = best_knn_4.score(X_test_new, y_test_new)\n",
    "print(f\"Test accuracy with best hyperparameter values: {test_accuracy:.4f}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "435a4805",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculating the accuract\n",
    "acc_score = accuracy_score(y_test, y_pred)\n",
    "print(f\"(OLD) Test accuracy with k={best_value_k} before hyper parameter tuning is {acc_score:.4f}.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
