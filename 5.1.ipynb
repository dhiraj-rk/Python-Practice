{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2344d54b",
   "metadata": {},
   "source": [
    "### Question.1. Using the MNIST Dataset, https://scikit-learn.org/stable/auto_examples/classification/plot_digits_classification.html train a classifier using each of the following:\n",
    "1. Decision Tree\n",
    "2. Ensemble of trees\n",
    "3. Random forest\n",
    "4. MLP Neural Network a. With 1 hidden layer b. With 2 hidden layers c. With 3 hidden layers\n",
    "You may experiment with choosing the other hyper-parameters for these models, however, anything that makes the model converge and work is sufficient for this exercise.\n",
    "Use cross-fold validation in order to evaluate the performance of each classifier on the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60290522",
   "metadata": {},
   "outputs": [],
   "source": [
    "#For imports\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_digits\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8244ed2f",
   "metadata": {},
   "source": [
    "### To load the data and visualize the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb31a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading the data\n",
    "digits = load_digits()\n",
    "print(digits.data.shape)\n",
    "features = digits.feature_names\n",
    "#print(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ce236da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting the 0th image in the dataset\n",
    "plt.gray()\n",
    "plt.matshow(digits.images[1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c545921",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reshape the data into one-dim arrays\n",
    "length = len(digits.images)\n",
    "digits_data = digits.images.reshape((length, -1))\n",
    "digits_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "689456d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Train Shape:\", digits_data.shape)\n",
    "print(\"Target shape:\", digits.target.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c56c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = digits_data.shape[0]\n",
    "n_features = digits_data.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc032a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data to train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(digits_data, digits.target, test_size = 0.25, shuffle = False, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3820b823",
   "metadata": {},
   "source": [
    "### 1.1. Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb28485",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtc = DecisionTreeClassifier(random_state = 42)\n",
    "dtc_model = dtc.fit(X_train, y_train)\n",
    "dtc_predict = dtc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "987fbb49",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, axes = plt.subplots(nrows=1, ncols=8, figsize=(12, 3))\n",
    "for ax, image, label in zip(axes, digits.images, dtc_predict):\n",
    "    ax.set_axis_off()\n",
    "    ax.imshow(image, cmap=plt.cm.gray_r, interpolation=\"nearest\")\n",
    "    ax.set_title(\"Prediction: %i\" % label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d73768d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hyperparameter tuning\n",
    "param_grid_dtc = {'min_samples_split' : range(10,500,20),\n",
    "                'max_depth': range(1,20,2),\n",
    "                 'criterion' : ['gini', 'entropy']}\n",
    "\n",
    "grid_dtc = GridSearchCV(dtc, param_grid = param_grid_dtc, refit = True, verbose = 2, n_jobs = 1)\n",
    "\n",
    "hyper_dtc = grid_dtc.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters for Decision Tree:\", grid_dtc.best_params_)\n",
    "\n",
    "scores_dtc = grid_dtc.cv_results_['mean_test_score'];\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a46f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Mean Test score for each combination:\", scores_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd78413",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using best parameters for testing\n",
    "dtc_best = DecisionTreeClassifier(criterion = 'gini', max_depth = 11, min_samples_split = 10)\n",
    "\n",
    "dtc_best_model = dtc_best.fit(X_train, y_train)\n",
    "\n",
    "dtc_best_pred = dtc_best_model.predict(X_test)\n",
    "\n",
    "dtc_test_accuracy = accuracy_score(y_test, dtc_best_pred)\n",
    "\n",
    "print(f\"Test accuracy with Decision Tree hyper parameter tuning: {dtc_test_accuracy: .2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a876445",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Cross validation for evaluation\n",
    "\n",
    "dtc_score = cross_val_score(dtc_best, digits_data, digits.target, cv = 5)\n",
    "\n",
    "for i, score in enumerate(dtc_score, start = 1):\n",
    "    print(f\"Fold {i} Test Accuracy: {score: .2%}\")\n",
    "    \n",
    "dtc_mean_score = np.mean(dtc_score)\n",
    "print(f\"Mean Test Accuracy score:{dtc_mean_score:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d4a747a",
   "metadata": {},
   "source": [
    "### 1.2. Ensemble of trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9583989e",
   "metadata": {},
   "outputs": [],
   "source": [
    "bag = BaggingClassifier(random_state = 1, n_jobs = -1)\n",
    "bag_model = bag.fit(X_train, y_train)\n",
    "bag_predict = bag_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e51762b",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, axes = plt.subplots(nrows=1, ncols=8, figsize=(12, 3))\n",
    "for ax, image, label in zip(axes, digits.images, bag_predict):\n",
    "    ax.set_axis_off()\n",
    "    ax.imshow(image, cmap=plt.cm.gray_r, interpolation=\"nearest\")\n",
    "    ax.set_title(\"Prediction: %i\" % label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec93c7d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c7704e",
   "metadata": {},
   "outputs": [],
   "source": [
    "params_grid_bag = {'estimator': [None, KNeighborsClassifier(), DecisionTreeClassifier()],\n",
    "          'n_estimators': [20,50,100],\n",
    "          'max_samples': [0.5, 1.0, n_samples//2,],\n",
    "          'max_features': [0.5, 1.0, n_features//2,],\n",
    "          'bootstrap': [True, False],\n",
    "          'bootstrap_features': [True, False]}\n",
    "\n",
    "grid_bag = GridSearchCV(bag, param_grid = params_grid_bag, cv = 3, n_jobs = -1, verbose = 2)\n",
    "\n",
    "hyper_bag = grid_bag.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters for Ensemble of trees with KNN and DT is:\", hyper_bag.best_params_)\n",
    "\n",
    "scores_bag = grid_bag.cv_results_['mean_test_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d86ccdd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Mean Test score with Ensemble for each combination:\", scores_bag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "107ddb60",
   "metadata": {},
   "outputs": [],
   "source": [
    "bag_best = BaggingClassifier(KNeighborsClassifier(), bootstrap = False, \n",
    "                             bootstrap_features = True, \n",
    "                             max_features = 1.0,\n",
    "                             max_samples = 1.0, \n",
    "                             n_estimators = 100)  \n",
    "\n",
    "#bag_best_model = hyper_bag.fit(X_train, y_train)\n",
    "bag_best_model = bag_best.fit(X_train, y_train)\n",
    "\n",
    "bag_best_pred = bag_best_model.predict(X_test)\n",
    "\n",
    "bag_test_accuracy = accuracy_score(y_test, bag_best_pred)\n",
    "\n",
    "print(f\"Test accuracy:{bag_test_accuracy:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eec7fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "bag_score = cross_val_score(bag_best, digits_data, digits.target, cv = 5)\n",
    "\n",
    "for i, score in enumerate(bag_score, start = 1):\n",
    "    print(f\"Fold {i} Test AccuracyL: {score:.2%}\")\n",
    "    \n",
    "bag_mean_score = np.mean(bag_score)\n",
    "print(f\"Mean Test Accuracy score:{bag_mean_score:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "242c684d",
   "metadata": {},
   "source": [
    "### 1.3. Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27c949a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(random_state = 42)\n",
    "rf_model = rf.fit(X_train, y_train)\n",
    "rf_predict = rf_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9f8f61f",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, axes = plt.subplots(nrows=1, ncols=8, figsize=(12, 3))\n",
    "for ax, image, label in zip(axes, digits.images, rf_predict):\n",
    "    ax.set_axis_off()\n",
    "    ax.imshow(image, cmap=plt.cm.gray_r, interpolation=\"nearest\")\n",
    "    ax.set_title(\"Prediction: %i\" % label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e04a6ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyper parameter\n",
    "param_grid_rf = {\"n_estimators\": [10, 50, 100],\n",
    "                \"max_depth\": [3, None],\n",
    "                \"max_features\": [\"sqrt\"],\n",
    "                \"min_samples_split\": [2,11],\n",
    "                \"min_samples_leaf\": [1,11],\n",
    "                \"bootstrap\": [True, False],\n",
    "                \"criterion\": [\"gini\", \"entropy\"]}\n",
    "\n",
    "grid_rf = GridSearchCV(rf, param_grid = param_grid_rf, cv = 5, n_jobs = 1, verbose = 2)\n",
    "\n",
    "hyper_rf = grid_rf.fit(X_train, y_train)\n",
    "\n",
    "scores_rf = grid_rf.cv_results_['mean_test_score']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3774bbef",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Mean Test score for each combination:\", scores_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46290f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyper_rf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef456fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model training with best parameters\n",
    "rf_best = RandomForestClassifier(bootstrap = False, criterion = 'entropy', max_depth = None, max_features = 'sqrt',\n",
    "                                 min_samples_leaf = 1, min_samples_split = 2, n_estimators = 100)\n",
    "\n",
    "rf_best_model = rf_best.fit(X_train, y_train)\n",
    "\n",
    "rf_best_pred = rf_best_model.predict(X_test)\n",
    "\n",
    "rf_test_accuracy = accuracy_score(y_test, rf_best_pred)\n",
    "\n",
    "print(f\"Test accuracy with Random Forest hyper parameter tuning: {rf_test_accuracy: .2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2678b3e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using cross validation\n",
    "\n",
    "rf_score = cross_val_score(rf_best, digits_data, digits.target, cv = 5)\n",
    "\n",
    "for i, score in enumerate(rf_score, start = 1):\n",
    "    print(f\"Fold {i} Test Accuracy:{score:.2%}\")\n",
    "\n",
    "rf_mean_score = np.mean(rf_score)\n",
    "print(f\"Mean Test Accuracy score:{rf_mean_score:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9e4b54d",
   "metadata": {},
   "source": [
    "### 1.4. MLP Neural Network \n",
    "1.4.a. With 1 hidden layer\n",
    "1.4.b. With 2 hidden layers\n",
    "1.4.c. With 3 hidden layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7936430",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLPClassifier(random_state = 42)\n",
    "mlp_model = mlp.fit(X_train, y_train)\n",
    "mlp_predict = mlp_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54b4f35c",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, axes = plt.subplots(nrows=1, ncols=8, figsize=(12, 3))\n",
    "for ax, image, label in zip(axes, digits.images, mlp_predict):\n",
    "    ax.set_axis_off()\n",
    "    ax.imshow(image, cmap=plt.cm.gray_r, interpolation=\"nearest\")\n",
    "    ax.set_title(\"Prediction: %i\" % label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25338ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyper parameter tuning with 1 layer\n",
    "param_grid_mlp_1_layer = {'hidden_layer_sizes': [(150,)],\n",
    "             'max_iter': [100, 200],\n",
    "             'activation': ['tanh', 'relu'],\n",
    "             'solver': ['sgd','adam'],\n",
    "             'alpha': [0.0001, 0.05],\n",
    "             'learning_rate': ['constant','adaptive']}\n",
    "\n",
    "grid_mlp_1_layer = GridSearchCV(mlp, param_grid = param_grid_mlp_1_layer, cv = 5, n_jobs = -1, verbose = 2)\n",
    "\n",
    "grid_mlp_1_layer.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters with 1 hidden layer for MLP:\", grid_mlp_1_layer.best_params_)\n",
    "\n",
    "scores_mlp_1_layer = grid_mlp_1_layer.cv_results_['mean_test_score']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf4f8ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Mean test scores for each combination with 1 layer:\", scores_mlp_1_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "884fc032",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyper parameter tuning with 2 layers\n",
    "param_grid_mlp_2_layer = {'hidden_layer_sizes': [(150,100)],\n",
    "             'max_iter': [100, 200],\n",
    "             'activation': ['tanh', 'relu'],\n",
    "             'solver': ['sgd', 'adam'],\n",
    "             'alpha': [0.0001, 0.05],\n",
    "             'learning_rate': ['constant','adaptive']}\n",
    "\n",
    "grid_mlp_2_layer = GridSearchCV(mlp, param_grid = param_grid_mlp_2_layer, cv = 5, n_jobs = -1, verbose = 2)\n",
    "\n",
    "grid_mlp_2_layer.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters with 2 hidden layers for MLP:\", grid_mlp_2_layer.best_params_)\n",
    "\n",
    "scores_mlp_2_layer = grid_mlp_2_layer.cv_results_['mean_test_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ce534ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Mean test scores for each combination with 2 layers:\", scores_mlp_2_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8320d579",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyper parameter tuning with 3 layers\n",
    "param_grid_mlp_3_layer = {'hidden_layer_sizes': [(150,100,50)],\n",
    "             'max_iter': [100, 200],\n",
    "             'activation': ['tanh', 'relu'],\n",
    "             'solver': ['sgd','adam'],\n",
    "             'alpha': [0.0001, 0.05],\n",
    "             'learning_rate': ['constant','adaptive']}\n",
    "\n",
    "grid_mlp_3_layer = GridSearchCV(mlp, param_grid = param_grid_mlp_3_layer, cv = 5, n_jobs = -1, verbose = 2)\n",
    "\n",
    "grid_mlp_3_layer.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters with 3 hidden layer for MLP:\", grid_mlp_3_layer.best_params_)\n",
    "\n",
    "scores_mlp_3_layer = grid_mlp_3_layer.cv_results_['mean_test_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3979332e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Mean test scores for each combination with 3 layers:\", scores_mlp_3_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f069c9ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluate the models\n",
    "#mlp_best_1_layer = MLPClassifier(activation = 'tanh', alpha = 0.05, hidden_layer_sizes = (150,), learning_rate = 'constant',\n",
    "                                # max_iter = 200, solver = 'adam')\n",
    "\n",
    "#mlp_best_1_layer_model = mlp_best_1_layer.fit(X_train, y_train)\n",
    "#print(f\"Test accuracy for MLP with 1 layer::::\", mlp_best_1_layer_model.score(X_test, y_test))\n",
    "\n",
    "mlp_1_layer_test_accuracy = grid_mlp_1_layer.score(X_test, y_test)\n",
    "mlp_2_layer_test_accuracy = grid_mlp_2_layer.score(X_test, y_test)\n",
    "mlp_3_layer_test_accuracy = grid_mlp_3_layer.score(X_test, y_test)\n",
    "\n",
    "print(f\"Test accuracy for MLP with 1 layer:{mlp_1_layer_test_accuracy:.2%}\")\n",
    "print(f\"Test accuracy for MLP with 2 layers:{mlp_2_layer_test_accuracy:.2%}\")\n",
    "print(f\"Test accuracy for MLP with 3 layers:{mlp_3_layer_test_accuracy:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54be7a90",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Best MLP is with 2 layers\n",
    "mlp_best = MLPClassifier(activation = 'relu', alpha = 0.05, hidden_layer_sizes = (150,100), learning_rate = 'constant',\n",
    "                                max_iter = 200, solver = 'adam')\n",
    "\n",
    "mlp_best_model = mlp_best.fit(X_train, y_train)\n",
    "\n",
    "mlp_score = cross_val_score(mlp_best, digits_data, digits.target, cv = 5)\n",
    "\n",
    "for i, score in enumerate(mlp_score, start = 1):\n",
    "    print(f\"Fold {i} Test Accuracy:{score:.2%}\")\n",
    "    \n",
    "mlp_mean_score = np.mean(mlp_score)\n",
    "print(f\"Mean Test Accuracy score:{mlp_mean_score:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e43046e0",
   "metadata": {},
   "source": [
    "### Question.2. Split a small amount of data off from the main training set for validation. For each classifier, find which label is predicted with the highest confidence over the validation set and plot the image and its predicted class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a82fd1cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting for validation set\n",
    "X_train, X_val, y_train, y_val = train_test_split(digits.data, digits.target, test_size = 0.1, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61760d81",
   "metadata": {},
   "source": [
    "### 2.1. Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "273297a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtc_val_predict = dtc_best.predict(X_val)\n",
    "dtc_confidence = dtc_best.predict_proba(X_val)\n",
    "dtc_best_labels = np.argmax(dtc_confidence, axis = 1)\n",
    "dtc_best_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25041652",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "for i in range(5):  # Plot the first 5 images\n",
    "    plt.subplot(2, 5, i + 1)\n",
    "    plt.imshow(X_val[i].reshape(8, 8), cmap='gray')\n",
    "    plt.title(f\"Predicted: {dtc_val_predict[i]}, Actual: {y_val[i]}\")\n",
    "\n",
    "plt.suptitle(\"Decision Tree - Predicted vs Actual\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33061970",
   "metadata": {},
   "source": [
    "### 2.2. Ensemble of trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98768cda",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bag_val_predict = bag_best.predict(X_val)\n",
    "bag_confidence = bag_best.predict_proba(X_val)\n",
    "bag_best_labels = np.argmax(bag_confidence, axis = 1)\n",
    "bag_best_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d2c020b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "for i in range(5):  # Plot the first 5 images\n",
    "    plt.subplot(2, 5, i + 1)\n",
    "    plt.imshow(X_val[i].reshape(8, 8), cmap='gray')\n",
    "    plt.title(f\"Predicted: {bag_val_predict[i]}, Actual: {y_val[i]}\")\n",
    "\n",
    "plt.suptitle(\"Ensemble of Trees (Bagging) - Predicted vs Actual\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "777b5137",
   "metadata": {},
   "source": [
    "### 2.3. Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24741c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_val_predict = rf_best.predict(X_val)\n",
    "rf_confidence = rf_best.predict_proba(X_val)\n",
    "rf_best_labels = np.argmax(rf_confidence, axis = 1)\n",
    "rf_best_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f6fc83f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "for i in range(5):  # Plot the first 5 images\n",
    "    plt.subplot(2, 5, i + 1)\n",
    "    plt.imshow(X_val[i].reshape(8, 8), cmap='gray')\n",
    "    plt.title(f\"Predicted: {rf_val_predict[i]}, Actual: {y_val[i]}\")\n",
    "\n",
    "plt.suptitle(\"Random Forest - Predicted vs Actual\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10b69ae7",
   "metadata": {},
   "source": [
    "### 2.4. MLP Neural Network\n",
    "2.4.a. With 1 hidden layer\n",
    "2.4.b. With 2 hidden layers\n",
    "2.4.c. With 3 hidden layers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1240448",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_val_predict = mlp_best.predict(X_val)\n",
    "mlp_confidence = mlp_best.predict_proba(X_val)\n",
    "mlp_best_labels = np.argmax(mlp_confidence, axis = 1)\n",
    "mlp_best_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "908abc2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "for i in range(5):  # Plot the first 5 images\n",
    "    plt.subplot(2, 5, i + 1)\n",
    "    plt.imshow(X_val[i].reshape(8, 8), cmap='gray')\n",
    "    plt.title(f\"Predicted: {mlp_best_labels[i]}, Actual: {y_val[i]}\")\n",
    "\n",
    "plt.suptitle(\"Random Forest - Predicted vs Actual\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
